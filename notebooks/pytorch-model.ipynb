{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Sklearn model using Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        x = X.values\n",
    "        y = y.values\n",
    "        self.x_train = torch.tensor(x, dtype=torch.float32)\n",
    "        self.y_train = torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.y_train)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return self.x_train[idx], self.y_train[idx]\n",
    "\n",
    "\n",
    "# Get my DataFrame\n",
    "df = pd.DataFrame(data={\n",
    "    \"a\": [1, 1, 0.5],\n",
    "    \"b\": [2.5, 2.7, 8],\n",
    "    \"target\": [0, 0, 1]\n",
    "})\n",
    "X = df.drop(\"target\", axis=1)\n",
    "y = df[\"target\"]\n",
    "\n",
    "# testing the dataloader\n",
    "# dataset = MyDataset(X, y)\n",
    "# data_loader = DataLoader(dataset, batch_size = 32, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "from torch import optim, nn\n",
    "import torchmetrics\n",
    "\n",
    "\n",
    "class LightningDeepLearning(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    Define the LightningModule\n",
    "    \"\"\"\n",
    "    def __init__(self, architecture):\n",
    "        super().__init__()\n",
    "        self.architecture = architecture\n",
    "        self.loss = nn.BCELoss()\n",
    "        self.accuracy = torchmetrics.Accuracy(task=\"binary\")\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        x, y = batch\n",
    "        pred = self.architecture(x)\n",
    "        # print(pred)\n",
    "        loss = self.loss(pred, y)\n",
    "\n",
    "        # log step metric\n",
    "        self.accuracy(pred, y)  # compute metrics\n",
    "        self.log('train_acc_step', self.accuracy)  # log metric object\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def forward(self, x):\n",
    "        pred = self.architecture(x)\n",
    "        return pred\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "# testint the model\n",
    "# input_size = 2\n",
    "# output_size = 1\n",
    "# architecture = nn.Sequential(\n",
    "#     nn.Linear(input_size, 64), nn.ReLU(),\n",
    "#     nn.Linear(64, output_size), nn.Sigmoid()\n",
    "# )\n",
    "\n",
    "# model = LightningDeepLearning(architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# architecture(torch.tensor([[0, 0], [0, 1]], dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model (hint: here are some helpful Trainer arguments for rapid idea iteration)\n",
    "# trainer = pl.Trainer(limit_train_batches = 100, max_epochs = 5)\n",
    "# trainer.fit(model = model, train_dataloaders = data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class TemplateClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, input_size, batch_size=32):\n",
    "        self.input_size = input_size\n",
    "        self.batch_size = batch_size\n",
    "        self.architecture = nn.Sequential(\n",
    "            nn.Linear(input_size, 64), nn.ReLU(),\n",
    "            nn.Linear(64, 1), nn.Sigmoid()\n",
    "        )\n",
    "        self.base = LightningDeepLearning(self.architecture)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Create dataloader\n",
    "        dataset = MyDataset(X, y)\n",
    "        data_loader = DataLoader(dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        # Train the model\n",
    "        trainer = pl.Trainer(max_epochs=10)\n",
    "        trainer.fit(model=self.base, train_dataloaders=data_loader)\n",
    "\n",
    "    def predict(self, X):\n",
    "        x = torch.tensor(X.values, dtype=torch.float32)\n",
    "        pred = self.base(x)\n",
    "        pred = pred.reshape(-1).detach().numpy().round().astype(np.int32)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/leonardo-moraes/Git/mlflow-recipes-titanic/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "\n",
      "  | Name         | Type           | Params\n",
      "------------------------------------------------\n",
      "0 | architecture | Sequential     | 257   \n",
      "1 | loss         | BCELoss        | 0     \n",
      "2 | accuracy     | BinaryAccuracy | 0     \n",
      "------------------------------------------------\n",
      "257       Trainable params\n",
      "0         Non-trainable params\n",
      "257       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "/home/leonardo-moraes/Git/mlflow-recipes-titanic/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/leonardo-moraes/Git/mlflow-recipes-titanic/.venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 84.40it/s, v_num=34] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 56.61it/s, v_num=34]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing my sklearn template\n",
    "my_estimator = TemplateClassifier(input_size=2)\n",
    "my_estimator.fit(X, y)\n",
    "my_estimator.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running a \"normal\" sklearn mode for comparison\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(random_state=0)\n",
    "model.fit(X, y)\n",
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
