# `recipe.yaml` is the main configuration file for an MLflow Recipe.
#
# Variables must be dereferenced in a profile YAML file, located under `profiles/`.
# See `profiles/local.yaml` for example usage. One may switch among profiles quickly by
# providing a profile name such as `local` in the Recipe object constructor:
# `r = Recipe(profile="local")`

recipe: "classification/v1"
# Specifies the target column name for model training and evaluation.
target_col: "Survived"
# Specifies the value of `target_col` that is considered the positive class.
positive_class: 1
# Sets the primary metric to use to evaluate model performance
# Built-in primary metrics are: recall_score, precision_score, f1_score, accuracy_score.
primary_metric: "accuracy_score"

steps:
  # Specifies the dataset to use for model development
  # It uses the `ingest.py` file
  ingest: {{INGEST_CONFIG}}

  split:
    # Adjust the train/validation/test split ratios below.
    split_ratios: [0.8, 0.1, 0.1]
    # Specifies the method to "data cleaning" the split datasets
    post_split_filter_method: dataset_row_filter

  transform:
    # Specifies the transformer method, sklearn-compatible
    using: "custom"
    transformer_method: transformer_fn

  train:
    # Specifies the method to use for training. Options are "automl/flaml" for
    # AutoML training or "custom" for user-defined estimators.
    # using: "automl/flaml" # it runs FLAML from Microsoft
    using: "custom"
    estimator_method: estimator_fn
    # calibrate_proba: isotonic # it is not working

  evaluate:
    # Sets performance thresholds to trained model be eligible for registration
    validation_criteria:
      - metric: accuracy_score
        threshold: 0.7
      - metric: f1_score
        threshold: 0.5
  register:
    # Indicates whether or not a model that fails to meet performance thresholds
    allow_non_validated_model: false

  # Optional: specify the dataset to use for batch scoring
  # It only works with Spark
  # ingest_scoring:
  #   using: "custom"
  #   location: ./data/input/test.csv
  #   loader_method: load_testset
  # predict:
  #   output:
  #     using: "parquet"
  #     location: ./data/output/submission.parquet
  #   result_type: "int"
  #   save_mode: "default"

# custom_metrics:
# Defines custom performance metrics to compute during model development
#     - name: ""
#       function: get_custom_metrics
#       greater_is_better: False
